{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "분류성능평가지표 - Precision(정밀도), Recall(재현율) and Accuracy(정확도)\n",
    "https://sumniya.tistory.com/26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.6366095581605\n"
     ]
    }
   ],
   "source": [
    "recall = 86\n",
    "prec = 91.44\n",
    "f1 = (2*recall*prec)/(recall+prec)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.6825"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(99.5+91+56+76.23)/4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label 교체\n",
    "new_test_label_ = torch.where(test_label_==3,torch.tensor([2]),test_label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertclass(origin_label, from_classes=[],to_class=[]):\n",
    "    converted_label = origin_label\n",
    "    for from_class in from_classes:\n",
    "        converted_label = torch.where(converted_label==from_class, torch.tensor([to_class[0]]), converted_label)# label 교체\n",
    "    return converted_label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Eval Calss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yjlib.ShowResult import ShowResult\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "class Evaluation():\n",
    "    \"\"\"Evaluation model\n",
    "    \n",
    "    init\n",
    "    ----\n",
    "    result dictionary\n",
    "        train loss and acc\n",
    "        test loss, acc, and classes add\n",
    "    \n",
    "    Methods\n",
    "    -------\n",
    "    train:\n",
    "    test:\n",
    "    reset_result:\n",
    "    save_result:\n",
    "    show_loss:\n",
    "    show_acc:\n",
    "    show_class_acc:\n",
    "    show_confusion_matrix:\n",
    "    show_roc:\n",
    "    show_heatmap:\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, NAME_OF_CLASS, device):\n",
    "        self.result = dict()\n",
    "        self.result[\"train_losses\"] = []\n",
    "        self.result[\"train_accuracyes\"] = []\n",
    "        \n",
    "        self.result[\"test_losses\"] = []\n",
    "        self.result[\"test_accuracyes\"] = []\n",
    "        self.result[\"test_class_acc\"] = []\n",
    "        \n",
    "        \n",
    "        self.result[\"test_label\"] = []\n",
    "        self.result[\"test_y_pred\"] = []\n",
    "        \n",
    "        self.device = device\n",
    "        self.showresult = ShowResult()\n",
    "        self.NAME_OF_CLASS = NAME_OF_CLASS\n",
    "        \n",
    "    # import tqdm\n",
    "    def train(self, model, optimizer,loss_func, data_loader, parallel_device_ids=[]):\n",
    "        \"\"\"Train for classification\n",
    "\n",
    "        Parameter\n",
    "        ---------\n",
    "        model: model\n",
    "        optimizer: optimizer\n",
    "        loss_func: loss_function\n",
    "        data_loader: data_loader\n",
    "        parallel_device_ids: [] Parallel device ids\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if len(parallel_device_ids) > 0 and torch.cuda.device_count() >= len(parallel_device_ids): \n",
    "            model = torch.nn.DataParallel(model)\n",
    "        elif torch.cuda.device_count() < len(parallel_device_ids): \n",
    "            print(\"ERROR: cuda.device < len(device_ids)\")\n",
    "\n",
    "        model.train()\n",
    "        model.to(self.device)\n",
    "\n",
    "        correct = 0\n",
    "\n",
    "        for batch_idx, (data, label) in enumerate(data_loader):\n",
    "            data, label = data.to(self.device), label.to(self.device)\n",
    "            data, label = Variable(data), Variable(label.long())\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad() \n",
    "\n",
    "            # forward + backward + optimize\n",
    "            output = model(data)\n",
    "    #         _, output_index = torch.max(output,1)# output: [0,1,0,...], output_index: 1\n",
    "            output = output.type(torch.FloatTensor)\n",
    "            label = label.type(torch.LongTensor)\n",
    "            label = label.view(-1)\n",
    "\n",
    "            loss = loss_func(output, label)\n",
    "            \"\"\"\n",
    "            Input: (N,C) where C = number of classes\n",
    "            Target: (N) where each value is 0 <= targets[i] <= C-1\n",
    "            Output: scalar. If reduce is False, then (N) instead.\n",
    "            \"\"\"\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pred = output.max(1)[1] # get the index of the max log-probability\n",
    "            correct += list(torch.eq(pred,label)).count(1)\n",
    "\n",
    "        self.result[\"train_losses\"].append(loss.item())\n",
    "        self.result[\"train_accuracyes\"].append(100. * correct / len(data_loader.dataset))\n",
    "        print('Train set: Loss: {:.6f}  Accuracy: {}/{} Total_ACC: ({:.2f}%)'.format(\n",
    "            loss.item(),\n",
    "            correct,\n",
    "            len(data_loader)*data_loader.batch_size,\n",
    "            100. * correct / len(data_loader)*data_loader.batch_size))\n",
    "    \n",
    "    # 2 classes\n",
    "    def test(self, model, loss_func, test_loader):\n",
    "        \"\"\"Classification test\n",
    "\n",
    "        Parameter\n",
    "        ---------\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        model.to(self.device)\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "\n",
    "        total_sample_counter = [0]* len(self.NAME_OF_CLASS)# 각 클래스별 sample 수를 counting\n",
    "        classes_correct_samples = [0]* len(self.NAME_OF_CLASS) # 각 클래별 맞는 sample 수\n",
    "\n",
    "        self.result[\"test_label\"] = torch.Tensor([]).type(torch.LongTensor) # dtype: torch.int64\n",
    "        self.result[\"test_y_pred\"] = torch.Tensor([]).type(torch.LongTensor) # dtype: torch.int64\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for idx,(data, label) in enumerate(test_loader):\n",
    "                data, label = data.to(self.device), label.to(self.device)\n",
    "                data, label = Variable(data), Variable(label.long())\n",
    "                output = model(data)\n",
    "                output = output.type(torch.FloatTensor)\n",
    "\n",
    "                label = label.type(torch.LongTensor)\n",
    "                label = label.view(-1) # dtype: torch.int64\n",
    "\n",
    "                test_loss += loss_func(output, label).item() # sum up batch loss\n",
    "\n",
    "                pred = output.max(1)[1] # get the index of the max log-probability # dtype: torch.int64\n",
    "\n",
    "                # 각 클래스별 데이터 총량 계산\n",
    "                for i in range(len(self.NAME_OF_CLASS)):\n",
    "                    total_sample_counter[i] += list(label).count(i)\n",
    "\n",
    "                # 맞는 전체 데이터 수 count\n",
    "                correct += list(torch.eq(pred,label)).count(1)\n",
    "                \n",
    "                self.result[\"test_label\"] = torch.cat((self.result[\"test_label\"], label), 0)\n",
    "                self.result[\"test_y_pred\"] = torch.cat((self.result[\"test_y_pred\"], pred), 0)\n",
    "\n",
    "                # 각 클래스별로 맞는 갯수\n",
    "                correct_indice = torch.eq(pred, label).nonzero().view(-1)\n",
    "                for i in range(len(self.NAME_OF_CLASS)):\n",
    "                    classes_correct_samples[i] += list(label[correct_indice]).count(i)\n",
    "\n",
    "        \n",
    "        \n",
    "        acc_dict = dict()\n",
    "        show_contents = []\n",
    "        # counting number of correct for each classes\n",
    "        for idx, name in enumerate(self.NAME_OF_CLASS):\n",
    "            acc_dict[name] = classes_correct_samples[idx]/total_sample_counter[idx]\n",
    "            show_contents.append(float(\"{0:.2f}\".format(classes_correct_samples[idx]/total_sample_counter[idx])))\n",
    "\n",
    "            \n",
    "        # evaluation number\n",
    "        acc_dict['average_acc'] = statistics.mean(acc_dict.values())\n",
    "#         acc_dict['precision'] =  # precision 삽입\n",
    "#         acc_dict['F-maeasure'] = # Multi class F-maeasure 삽입 예정 \n",
    "\n",
    "        self.result[\"test_class_acc\"].append(acc_dict)\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "\n",
    "        self.result[\"test_losses\"].append(test_loss)\n",
    "        self.result[\"test_accuracyes\"].append(100. * acc_dict[\"average_acc\"])\n",
    "\n",
    "        show_title =  self.NAME_OF_CLASS + ['Average loss','Average Accuracy']\n",
    "        show_contents += [float(\"{0:.6f}\".format(test_loss)),\n",
    "                              float(\"{0:.2f}\".format(100. * acc_dict[\"average_acc\"]))]\n",
    "        self.__print_result(show_title,show_contents)\n",
    "                                 \n",
    "        del show_contents, show_title\n",
    "        \n",
    "    def __print_result(self, title=[],contents=[]):\n",
    "        print(\"Test set\")\n",
    "        assert len(title) == len(contents)\n",
    "                                 \n",
    "        # 클래스 별로 결과값 별로 pretty table 을 show\n",
    "        info_table = PrettyTable(title)\n",
    "        info_table.add_row(contents)\n",
    "        \n",
    "        print(info_table)\n",
    "\n",
    "    def reset_result(self):\n",
    "        \"\"\"Reset result\n",
    "        reset the result dictionary\n",
    "        \"\"\"\n",
    "        print(\"reset result dictionary\")\n",
    "        self.result = dict()\n",
    "        self.result[\"train_losses\"] = []\n",
    "        self.result[\"train_accuracyes\"] = []\n",
    "        \n",
    "        self.result[\"test_losses\"] = []\n",
    "        self.result[\"test_accuracyes\"] = []\n",
    "        self.result[\"test_class_acc\"] = []\n",
    "\n",
    "        self.result[\"test_label\"] = torch.Tensor([]).type(torch.LongTensor)\n",
    "        self.result[\"test_y_pred\"] = torch.Tensor([]).type(torch.LongTensor)\n",
    "        \n",
    "    def save_result(self, path):\n",
    "        \"\"\"Save result of acc and class acc\n",
    "        Parameter\n",
    "        --------\n",
    "        path: absolute path for saving\n",
    "        \"\"\"\n",
    "        print(\"saving result to csv\")\n",
    "        \n",
    "    def show_loss(self):\n",
    "        print(\"show loss\")\n",
    "        #loss\n",
    "        data_list = [[x / 100 for x in self.result['train_losses']],\n",
    "                     [x / 100 for x in self.result['test_losses']]]\n",
    "        title = 'Loss Plot'\n",
    "        ylabel = 'Loss'  \n",
    "        tag = ['train','test']\n",
    "        loc=  'best'\n",
    "        xlabel = 'epoch'\n",
    "\n",
    "        for i in range(len(data_list)):\n",
    "            plt.plot(data_list[i])\n",
    "\n",
    "        plt.legend(tag,loc=loc)\n",
    "        plt.title(title)\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.xlabel(xlabel)\n",
    "        plt.show()\n",
    "        \n",
    "    def show_acc(self):\n",
    "        print(\"show acc\")\n",
    "        data_list = [[x / 100 for x in self.result['train_accuracyes']],\n",
    "                     [x / 100 for x in self.result['test_accuracyes']]]\n",
    "        title = 'Accuracy Plot'\n",
    "        ylabel = 'Accuracy'   \n",
    "        tag = ['train','test']\n",
    "        loc=  'best'\n",
    "        xlabel = 'epoch'\n",
    "\n",
    "        for i in range(len(data_list)):\n",
    "            plt.plot(data_list[i])\n",
    "\n",
    "        ylim = [0,1]\n",
    "        plt.legend(tag,loc=loc)\n",
    "        plt.title(title)\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.xlabel(xlabel)\n",
    "        plt.ylim(ylim)\n",
    "        plt.show()\n",
    "        \n",
    "    def show_class_acc(self):\n",
    "        print(\"show class acc\")\n",
    "        \n",
    "        class_acc = dict()\n",
    "        for name in self.NAME_OF_CLASS:\n",
    "            class_acc[name] = []\n",
    "        \n",
    "        class_acc_result = []\n",
    "        \n",
    "        for dic in self.result[\"test_class_acc\"]:\n",
    "            # dictionary for each epoch\n",
    "            for name in self.NAME_OF_CLASS:\n",
    "                class_acc[name].append(dic[name])\n",
    "\n",
    "        # class accuracy\n",
    "        data_list = []\n",
    "        for name in self.NAME_OF_CLASS:\n",
    "            data_list.append(class_acc[name])\n",
    "            \n",
    "        title='Classes Accuracy'\n",
    "        ylabel='Accuracy'\n",
    "        # tag = ['Normal','lgd','hgd','cancer']a\n",
    "        tag = self.NAME_OF_CLASS\n",
    "\n",
    "        loc=  'best'\n",
    "        xlabel = 'epoch'\n",
    "\n",
    "        for i in range(len(data_list)):\n",
    "            plt.plot(data_list[i])\n",
    "\n",
    "        ylim = [0,1]\n",
    "        plt.legend(tag,loc=loc)\n",
    "        plt.title(title)\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.xlabel(xlabel)\n",
    "        plt.ylim(ylim)\n",
    "        plt.show()\n",
    "        \n",
    "    def show_confusion_matrix(self):\n",
    "        print(\"show confusion matrix\")\n",
    "        self.cm = self.showresult.plot_confusion_matrix(self.NAME_OF_CLASS,\n",
    "                                 label=self.result[\"test_label\"], \n",
    "                                 predic=self.result[\"test_y_pred\"])\n",
    "        \n",
    "    def show_roc(self):\n",
    "        print(\"roc result\")\n",
    "        print(self.cm.T)\n",
    "#         cm = self.cm.T\n",
    "        \n",
    "        \n",
    "    \n",
    "    def show_heatmap(self, data_path):\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        print(\"show heatmap\")\n",
    "    def count_time(self):\n",
    "        \"\"\"\n",
    "        Calculate time\n",
    "        \n",
    "        \"\"\"\n",
    "        start_t = datetime.datetime.now()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double label Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yjlib.ShowResult import ShowResult\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "class Evaluation():\n",
    "    \"\"\"Evaluation model\n",
    "    \n",
    "    init\n",
    "    ----\n",
    "    result dictionary\n",
    "        train loss and acc\n",
    "        test loss, acc, and classes add\n",
    "    \n",
    "    Methods\n",
    "    -------\n",
    "    train:\n",
    "    test:\n",
    "    reset_result:\n",
    "    save_result:\n",
    "    show_loss:\n",
    "    show_acc:\n",
    "    show_class_acc:\n",
    "    show_confusion_matrix:\n",
    "    show_roc:\n",
    "    show_heatmap:\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, NAME_OF_CLASS, device):\n",
    "        self.result = dict()\n",
    "        self.result[\"train_losses\"] = []\n",
    "        self.result[\"train_accuracyes\"] = []\n",
    "        \n",
    "        self.result[\"test_losses\"] = []\n",
    "        self.result[\"test_accuracyes\"] = []\n",
    "        self.result[\"test_class_acc\"] = []\n",
    "        \n",
    "        self.result[\"test_label\"] = []\n",
    "        self.result[\"test_y_pred\"] = []\n",
    "        \n",
    "        self.result['match_path'] = []\n",
    "        self.result['match_label'] = torch.Tensor([]).type(torch.LongTensor)\n",
    "\n",
    "        self.result['unmatch_path'] = []\n",
    "        self.result['unmatch_label'] = torch.Tensor([]).type(torch.LongTensor)\n",
    "\n",
    "        self.device = device\n",
    "        self.showresult = ShowResult()\n",
    "        self.NAME_OF_CLASS = NAME_OF_CLASS\n",
    "        \n",
    "    # import tqdm\n",
    "    def train(self, model, optimizer,loss_func, data_loader, parallel_device_ids=[]):\n",
    "        \"\"\"Train for classification\n",
    "\n",
    "        Parameter\n",
    "        ---------\n",
    "        model: model\n",
    "        optimizer: optimizer\n",
    "        loss_func: loss_function\n",
    "        data_loader: data_loader\n",
    "        parallel_device_ids: [] Parallel device ids\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if len(parallel_device_ids) > 0 and torch.cuda.device_count() >= len(parallel_device_ids): \n",
    "            model = torch.nn.DataParallel(model)\n",
    "        elif torch.cuda.device_count() < len(parallel_device_ids): \n",
    "            print(\"ERROR: cuda.device < len(device_ids)\")\n",
    "\n",
    "        model.train()\n",
    "        model.to(self.device)\n",
    "\n",
    "        correct = 0\n",
    "\n",
    "        for batch_idx, (data, label) in enumerate(data_loader):\n",
    "            data, label = data.to(self.device), label.to(self.device)\n",
    "            data, label = Variable(data), Variable(label.long())\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad() \n",
    "\n",
    "            # forward + backward + optimize\n",
    "            output = model(data)\n",
    "    #         _, output_index = torch.max(output,1)# output: [0,1,0,...], output_index: 1\n",
    "            output = output.type(torch.FloatTensor)\n",
    "            label = label.type(torch.LongTensor)\n",
    "            label = label.view(-1)\n",
    "\n",
    "            loss = loss_func(output, label)\n",
    "            \"\"\"\n",
    "            Input: (N,C) where C = number of classes\n",
    "            Target: (N) where each value is 0 <= targets[i] <= C-1\n",
    "            Output: scalar. If reduce is False, then (N) instead.\n",
    "            \"\"\"\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pred = output.max(1)[1] # get the index of the max log-probability\n",
    "            correct += list(torch.eq(pred,label)).count(1)\n",
    "\n",
    "        self.result[\"train_losses\"].append(loss.item())\n",
    "        self.result[\"train_accuracyes\"].append(100. * correct / len(data_loader.dataset))\n",
    "        print('Train set: Loss: {:.6f}  Accuracy: {}/{} Total_ACC: ({:.2f}%)'.format(\n",
    "            loss.item(),\n",
    "            correct,\n",
    "            len(data_loader)*data_loader.batch_size,\n",
    "            100. * correct / len(data_loader)*data_loader.batch_size))\n",
    "    \n",
    "    # 2 classes\n",
    "    def test(self, model, loss_func, test_loader):\n",
    "        \"\"\"Classification test\n",
    "\n",
    "        Parameter\n",
    "        ---------\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        model.to(self.device)\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "\n",
    "        total_sample_counter = [0]* len(self.NAME_OF_CLASS)# 각 클래스별 sample 수를 counting\n",
    "        classes_correct_samples = [0]* len(self.NAME_OF_CLASS) # 각 클래별 맞는 sample 수\n",
    "\n",
    "        self.result[\"test_label\"] = torch.Tensor([]).type(torch.LongTensor) # dtype: torch.int64\n",
    "        self.result[\"test_y_pred\"] = torch.Tensor([]).type(torch.LongTensor) # dtype: torch.int64\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for idx,(data, label, pathes) in enumerate(test_loader):\n",
    "                data, label = data.to(self.device), label.to(self.device)\n",
    "                data, label = Variable(data), Variable(label.long())\n",
    "                output = model(data)\n",
    "                output = output.type(torch.FloatTensor)\n",
    "\n",
    "                label = label.type(torch.LongTensor)\n",
    "                label = label.view(-1) # dtype: torch.int64\n",
    "                \n",
    "                # XXXX 표준화 필요\n",
    "                new_label = self.__convertclass(label, from_classes=[3], to_class=[2])\n",
    "                # XXXX 표준화 필요\n",
    "\n",
    "                test_loss += loss_func(output, new_label).item() # sum up batch loss\n",
    "\n",
    "                pred = output.max(1)[1] # get the index of the max log-probability # dtype: torch.int64\n",
    "\n",
    "                # 각 클래스별 데이터 총량 계산\n",
    "                for i in range(len(self.NAME_OF_CLASS)):\n",
    "                    total_sample_counter[i] += list(label).count(i)\n",
    "\n",
    "                # 맞는 전체 데이터 수 count\n",
    "                correct += list(torch.eq(pred,label)).count(1)\n",
    "                \n",
    "                torch.eq(pred,label)\n",
    "                \n",
    "                # torch.eq(pred, label) 결과로 index 뽑기\n",
    "                match_indic = torch.eq(pred,new_label)\n",
    "\n",
    "                # path 및 label 저장 하기 \n",
    "                self.result['match_path'] += [path for match, path in zip(match_indic,pathes) if match==True]\n",
    "                self.result['match_label'] = torch.cat((self.result['match_label'],label[match_indic==True])) \n",
    "\n",
    "                self.result['unmatch_path'] += [path for match, path in zip(match_indic,pathes) if match==False]\n",
    "                self.result['unmatch_label'] = torch.cat((self.result['unmatch_label'],label[match_indic==False])) \n",
    "                \n",
    "                self.result[\"test_label\"] = torch.cat((self.result[\"test_label\"], new_label), 0)\n",
    "                self.result[\"test_y_pred\"] = torch.cat((self.result[\"test_y_pred\"], pred), 0)\n",
    "\n",
    "                # 각 클래스별로 맞는 갯수\n",
    "                correct_indice = torch.eq(pred, label).nonzero().view(-1)\n",
    "                for i in range(len(self.NAME_OF_CLASS)):\n",
    "                    classes_correct_samples[i] += list(label[correct_indice]).count(i)\n",
    "\n",
    "        \n",
    "        \n",
    "        acc_dict = dict()\n",
    "        show_contents = []\n",
    "        # counting number of correct for each classes\n",
    "        for idx, name in enumerate(self.NAME_OF_CLASS):\n",
    "            acc_dict[name] = classes_correct_samples[idx]/total_sample_counter[idx]\n",
    "            show_contents.append(float(\"{0:.2f}\".format(classes_correct_samples[idx]/total_sample_counter[idx])))\n",
    "\n",
    "            \n",
    "        # evaluation number\n",
    "        acc_dict['average_acc'] = statistics.mean(acc_dict.values())\n",
    "#         acc_dict['precision'] =  # precision 삽입\n",
    "#         acc_dict['F-maeasure'] = # Multi class F-maeasure 삽입 예정 \n",
    "\n",
    "        self.result[\"test_class_acc\"].append(acc_dict)\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "\n",
    "        self.result[\"test_losses\"].append(test_loss)\n",
    "        self.result[\"test_accuracyes\"].append(100. * acc_dict[\"average_acc\"])\n",
    "\n",
    "        show_title =  self.NAME_OF_CLASS + ['Average loss','Average Accuracy']\n",
    "        show_contents += [float(\"{0:.6f}\".format(test_loss)),\n",
    "                              float(\"{0:.2f}\".format(100. * acc_dict[\"average_acc\"]))]\n",
    "        self.__print_result(show_title,show_contents)\n",
    "                                 \n",
    "        del show_contents, show_title\n",
    "    \n",
    "    def __convertclass(self, origin_label, from_classes=[],to_class=[]):\n",
    "        converted_label = origin_label\n",
    "        for from_class in from_classes:\n",
    "            converted_label = torch.where(converted_label==from_class, torch.tensor([to_class[0]]), converted_label)# label 교체\n",
    "        return converted_label\n",
    "\n",
    "    def __print_result(self, title=[],contents=[]):\n",
    "        print(\"Test set\")\n",
    "        assert len(title) == len(contents)\n",
    "                                 \n",
    "        # 클래스 별로 결과값 별로 pretty table 을 show\n",
    "        info_table = PrettyTable(title)\n",
    "        info_table.add_row(contents)\n",
    "        \n",
    "        print(info_table)\n",
    "\n",
    "    def reset_result(self):\n",
    "        \"\"\"Reset result\n",
    "        reset the result dictionary\n",
    "        \"\"\"\n",
    "        print(\"reset result dictionary\")\n",
    "        self.result = dict()\n",
    "        self.result[\"train_losses\"] = []\n",
    "        self.result[\"train_accuracyes\"] = []\n",
    "        \n",
    "        self.result[\"test_losses\"] = []\n",
    "        self.result[\"test_accuracyes\"] = []\n",
    "        self.result[\"test_class_acc\"] = []\n",
    "\n",
    "        self.result[\"test_label\"] = torch.Tensor([]).type(torch.LongTensor)\n",
    "        self.result[\"test_y_pred\"] = torch.Tensor([]).type(torch.LongTensor)\n",
    "        \n",
    "        self.result['match_path'] = []\n",
    "        self.result['match_label'] = torch.Tensor([]).type(torch.LongTensor)\n",
    "\n",
    "        self.result['unmatch_path'] = []\n",
    "        self.result['unmatch_label'] = torch.Tensor([]).type(torch.LongTensor)\n",
    "        \n",
    "    def save_result(self, path):\n",
    "        \"\"\"Save result of acc and class acc\n",
    "        Parameter\n",
    "        --------\n",
    "        path: absolute path for saving\n",
    "        \"\"\"\n",
    "        print(\"saving result to csv\")\n",
    "        \n",
    "    def show_loss(self):\n",
    "        print(\"show loss\")\n",
    "        #loss\n",
    "        data_list = [[x / 100 for x in self.result['train_losses']],\n",
    "                     [x / 100 for x in self.result['test_losses']]]\n",
    "        title = 'Loss Plot'\n",
    "        ylabel = 'Loss'  \n",
    "        tag = ['train','test']\n",
    "        loc=  'best'\n",
    "        xlabel = 'epoch'\n",
    "\n",
    "        for i in range(len(data_list)):\n",
    "            plt.plot(data_list[i])\n",
    "\n",
    "        plt.legend(tag,loc=loc)\n",
    "        plt.title(title)\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.xlabel(xlabel)\n",
    "        plt.show()\n",
    "        \n",
    "    def show_acc(self):\n",
    "        print(\"show acc\")\n",
    "        data_list = [[x / 100 for x in self.result['train_accuracyes']],\n",
    "                     [x / 100 for x in self.result['test_accuracyes']]]\n",
    "        title = 'Accuracy Plot'\n",
    "        ylabel = 'Accuracy'   \n",
    "        tag = ['train','test']\n",
    "        loc=  'best'\n",
    "        xlabel = 'epoch'\n",
    "\n",
    "        for i in range(len(data_list)):\n",
    "            plt.plot(data_list[i])\n",
    "\n",
    "        ylim = [0,1]\n",
    "        plt.legend(tag,loc=loc)\n",
    "        plt.title(title)\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.xlabel(xlabel)\n",
    "        plt.ylim(ylim)\n",
    "        plt.show()\n",
    "        \n",
    "    def show_class_acc(self):\n",
    "        print(\"show class acc\")\n",
    "        \n",
    "        class_acc = dict()\n",
    "        for name in self.NAME_OF_CLASS:\n",
    "            class_acc[name] = []\n",
    "        \n",
    "        class_acc_result = []\n",
    "        \n",
    "        for dic in self.result[\"test_class_acc\"]:\n",
    "            # dictionary for each epoch\n",
    "            for name in self.NAME_OF_CLASS:\n",
    "                class_acc[name].append(dic[name])\n",
    "\n",
    "        # class accuracy\n",
    "        data_list = []\n",
    "        for name in self.NAME_OF_CLASS:\n",
    "            data_list.append(class_acc[name])\n",
    "            \n",
    "        title='Classes Accuracy'\n",
    "        ylabel='Accuracy'\n",
    "        # tag = ['Normal','lgd','hgd','cancer']a\n",
    "        tag = self.NAME_OF_CLASS\n",
    "\n",
    "        loc=  'best'\n",
    "        xlabel = 'epoch'\n",
    "\n",
    "        for i in range(len(data_list)):\n",
    "            plt.plot(data_list[i])\n",
    "\n",
    "        ylim = [0,1]\n",
    "        plt.legend(tag,loc=loc)\n",
    "        plt.title(title)\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.xlabel(xlabel)\n",
    "        plt.ylim(ylim)\n",
    "        plt.show()\n",
    "        \n",
    "    def show_confusion_matrix(self):\n",
    "        print(\"show confusion matrix\")\n",
    "        self.cm = self.showresult.plot_confusion_matrix(self.NAME_OF_CLASS,\n",
    "                                 label=self.result[\"test_label\"], \n",
    "                                 predic=self.result[\"test_y_pred\"])\n",
    "        \n",
    "    def show_roc(self):\n",
    "        print(\"roc result\")\n",
    "        print(self.cm.T)\n",
    "#         cm = self.cm.T\n",
    "        \n",
    "        \n",
    "    \n",
    "    def show_heatmap(self, data_path):\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        print(\"show heatmap\")\n",
    "    def count_time(self):\n",
    "        \"\"\"\n",
    "        Calculate time\n",
    "        \n",
    "        \"\"\"\n",
    "        start_t = datetime.datetime.now()\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
