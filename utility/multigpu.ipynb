{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEVICE_IDS = [0, 1, 2,3,4,5,6,7]\n",
    "# DEVICE_IDS = [0, 1, 2,3,4]\n",
    "# DEVICE_IDS = [0, 1, 2,3]\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "# DEVICE_IDS = [0,1,2]\n",
    "DEVICE_IDS = [0]\n",
    "BATCHSIZE = 1000 * len(DEVICE_IDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCHSIZE, shuffle=False)\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    \"Implementation Ref: https://github.com/kuangliu/pytorch-cifar\"\n",
    "    def __init__(self):\n",
    "        super(VGG, self).__init__()\n",
    "        VGG16 = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', \n",
    "                 512, 512, 512, 'M', 512, 512, 512, 'M']\n",
    "        self.features = self._make_layers(VGG16)\n",
    "        self.classifier = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
    "                           nn.BatchNorm2d(x),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = x\n",
    "        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "net = VGG()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "device = \"cuda\"\n",
    "torch.cuda.set_device(0)\n",
    "net.to(device);\n",
    "net = nn.DataParallel(net, device_ids=DEVICE_IDS)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training starts...\n"
     ]
    }
   ],
   "source": [
    "print('Training starts...')\n",
    "start = datetime.datetime.now()\n",
    "for epoch in range(5):  # loop over the dataset multiple times\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        \n",
    "        inputs, labels = inputs.cuda(device, async=True), labels.cuda(device, async=True)\n",
    "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(labels)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print('[{:d}, {:5f}]'.format(epoch+1, loss.item()))\n",
    "finish = datetime.datetime.now()\n",
    "print('Done.. Duration: ',finish - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training starts...\n",
      "[1, 1.966122]\n",
      "[2, 1.615373]\n",
      "[3, 1.402906]\n",
      "[4, 1.255466]\n"
     ]
    }
   ],
   "source": [
    "print('Training starts...')\n",
    "start = datetime.datetime.now()\n",
    "for epoch in range(5):  # loop over the dataset multiple times\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        \n",
    "        inputs, labels = inputs.cuda(device, async=True), labels.cuda(device, async=True)\n",
    "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(labels)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print('[{:d}, {:5f}]'.format(epoch+1, loss.item()))\n",
    "finish = datetime.datetime.now()\n",
    "print('Done.. Duration: ',finish - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training starts...\n",
      "[1, 2.045465]\n",
      "[2, 1.753967]\n",
      "[3, 1.571599]\n",
      "[4, 1.416739]\n",
      "[5, 1.287294]\n",
      "Done.. Duration:  0:02:38.597538\n"
     ]
    }
   ],
   "source": [
    "print('Training starts...')\n",
    "start = datetime.datetime.now()\n",
    "for epoch in range(5):  # loop over the dataset multiple times\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        \n",
    "        inputs, labels = inputs.cuda(device, async=True), labels.cuda(device, async=True)\n",
    "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(labels)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print('[{:d}, {:5f}]'.format(epoch+1, loss.item()))\n",
    "finish = datetime.datetime.now()\n",
    "print('Done.. Duration: ',finish - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training starts...')\n",
    "start = datetime.datetime.now()\n",
    "for epoch in range(5):  # loop over the dataset multiple times\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        \n",
    "        inputs, labels = inputs.cuda(device, async=True), labels.cuda(device, async=True)\n",
    "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(labels)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print('[{:d}, {:5f}]'.format(epoch+1, loss.item()))\n",
    "finish = datetime.datetime.now()\n",
    "print('Done.. Duration: ',finish - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training starts...\n",
      "[1, 2.238004]\n",
      "[2, 2.004407]\n",
      "[3, 1.821976]\n",
      "[4, 1.673215]\n",
      "[5, 1.554240]\n",
      "Done.. Duration:  0:01:38.230195\n"
     ]
    }
   ],
   "source": [
    "print('Training starts...')\n",
    "start = datetime.datetime.now()\n",
    "for epoch in range(5):  # loop over the dataset multiple times\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        \n",
    "        inputs, labels = inputs.cuda(device, async=True), labels.cuda(device, async=True)\n",
    "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(labels)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print('[{:d}, {:5f}]'.format(epoch+1, loss.item()))\n",
    "finish = datetime.datetime.now()\n",
    "print('Done.. Duration: ',finish - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
